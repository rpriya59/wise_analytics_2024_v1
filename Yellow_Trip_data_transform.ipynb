{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfe847-68bb-48f5-bc36-b505c51a47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and analysis the Data for Yellow Taxi trips for the Month of Janaury 2024 #\n",
    "# Release Version 1.0, 2024-10-01# \n",
    "# Author:Lakshmi Priya #\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from google.cloud import bigquery\n",
    "import pyarrow\n",
    "import os \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/lravin667/Downloads/decisive-scion-437014-c8-d5fd4b94b067.json'\n",
    "from google.cloud import storage\n",
    "\n",
    "\"\"\"\n",
    "To Transform the data to calculate the below additional fields,\n",
    "   1. Trip Duration  - To get the duration of each trip in minutes/seconds\n",
    "   2. Fare Amount    - Calculate the fare amount per mile to analyse price trends\n",
    "   3. Flag           - Value of High for trips with unusually high fares or long distances for further investigation\n",
    "   4. Total Fare     - Calculate the total fare of the trip\n",
    "   5. Total surcharges- Aggregate various surcharge amounts\n",
    "   6. Day/night ind  - Calcaute the indicator, \n",
    "                       if the hour of trip is between 6 AM to 18 PM its marked as \"Day\"\n",
    "                       if the hour of trip is between 18 PM to 6 AM its marked as \"Night\"\n",
    "   7. Weekday        - calculate the weekday when the trip was taken.\n",
    "                    0 -'Monday', 1-'Tuesday', 2 -'Wednesday', 3-'Thursday', 4-'Friday', 5-'Saturday', 6-'Sunday'\n",
    "   8. Rush hour     - calculate the rush hour indicator \n",
    "                      if the hour of trip is between 7 AM to 9 AM or 16 PM to 19 PM its marked as \"Yes\"\n",
    "                      if the hour of trip is between 9 AM to 16 PM or 19 PM to 7 AM its marked as \"No\"\n",
    "   9. Daily Summary - Calculate the daily summary of data for the month of January on the following columns,\n",
    "                      Total distance covered on all trips on the given day\n",
    "                      Total amount earned on the day\n",
    "                      Passengar count on the given day\n",
    " \n",
    "\"\"\"\n",
    "def transform(gcs_parquet_file_path):\n",
    "    # Read the Parquet file into a pandas DataFrame\n",
    "    df = pd.read_parquet(gcs_parquet_file_path)\n",
    "\n",
    "    #1 Calculate Trip Duration\n",
    "\n",
    "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    #trip_duration=df['trip_duration']\n",
    "    #print(trip_duration)\n",
    "    \n",
    "    #2 Calculate fare per mile\n",
    "    df['fare_per_mile'] = df['fare_amount'] / df['trip_distance'].replace(0, 1)  # Avoid division by zero\n",
    "    #fare_per_mile=df['fare_per_mile']\n",
    "    #print(fare_per_mile)\n",
    "\n",
    "    #3 mark the high fare trips \n",
    "    q1 = df['trip_distance'].quantile(0.25)\n",
    "    q3 = df['trip_distance'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    df['high_fare_trips'] = ((df['trip_distance'] >= (q1 - 1.5 * iqr)) & (df['trip_distance'] <= (q3 + 1.5 * iqr))).astype(int)\n",
    "    df['high_fare_trips']=df['high_fare_trips'].replace({0:'High',1:'Low'})\n",
    "    \n",
    "    #4 Calculate the Total fare of the trip\n",
    "    df['total_fare'] = df[['fare_amount', 'tip_amount', 'extra', 'mta_tax', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'Airport_fee']].sum(axis=1)\n",
    "\n",
    "    #5 Calculate total surcharge\n",
    "    df['total_surcharge'] = df[['extra', 'mta_tax', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'Airport_fee']].sum(axis=1)\n",
    "\n",
    "    #6 To calculate Day/night indicator\n",
    "    df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df['day_night_trip'] = df['pickup_hour'].apply(lambda x: 'Day'if 6 <= x <= 18 else'Night')\n",
    "\n",
    "    #7 To calculate the Week day of the trip\n",
    "    df['pickup_day_of_week'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "\n",
    "    #8 To calculate the rush hour \n",
    "    df['rush_hour'] = df['pickup_hour'].apply(lambda x: 'Yes'if (7 <= x <= 9) or (16 <= x <= 19) else 'No')\n",
    "\n",
    "    #9 daily summary\n",
    "    daily_summary = df.groupby(df['tpep_pickup_datetime'].dt.date).agg({\n",
    "    'trip_distance': 'sum',\n",
    "    'total_amount': 'sum',\n",
    "    'passenger_count': 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "def calc_daily_summary(df):\n",
    "\n",
    "    # Calculate daily summary\n",
    "    daily_summary = df.groupby(df['tpep_pickup_datetime'].dt.date).agg({\n",
    "        'trip_distance': 'sum',\n",
    "        'total_amount': 'sum',\n",
    "        'passenger_count': 'sum'\n",
    "    }).reset_index()\n",
    "    print('Daily Summary of Trip data For Janaury')\n",
    "    print(daily_summary)\n",
    "    \n",
    "    \n",
    "def load_parquet_to_partitioned_bigquery(dataset_id, table_id, df, partition_column):\n",
    "    # Initialize the BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Create a job configuration for loading the Parquet file\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.PARQUET,\n",
    "        # Specify partitioning\n",
    "        time_partitioning=bigquery.TimePartitioning(\n",
    "            field=partition_column,  # The column to partition by\n",
    "            type_=bigquery.TimePartitioningType.DAY,  # Partitioning type (DAY, MONTH, YEAR)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Load the data into the partitioned BigQuery table\n",
    "    load_job = client.load_table_from_dataframe(\n",
    "        df,\n",
    "        f'{client.project}.{dataset_id}.{table_id}'\n",
    "    )\n",
    "\n",
    "    # Wait for the job to complete\n",
    "    load_job.result()\n",
    "\n",
    "    # Output the result\n",
    "    print(f'Loaded {load_job.output_rows} rows into {dataset_id}.{table_id}.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    gcs_parquet_file_path ='gs://lakshmi_test1/yellow_tripdata_2024-01.parquet'  \n",
    "\n",
    "    #Transform the input dataset\n",
    "    df=transform(gcs_parquet_file_path)\n",
    "\n",
    "    # Load the dataset into a table \n",
    "    dataset_id = 'yellow_tripdata'  # dataset ID\n",
    "    table_id = 'yellow_trip_xref_table'       # table ID\n",
    "    partition_column='VendorID'  #partition column on which table will be partitioned\n",
    "\n",
    "    load_parquet_to_partitioned_bigquery(dataset_id, table_id, df,partition_column)\n",
    "\n",
    "    #Generate Daily summary\n",
    "    calc_daily_summary(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
